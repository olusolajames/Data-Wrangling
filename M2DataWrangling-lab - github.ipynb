{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify duplicate values in the dataset.\n",
    "\n",
    "-   Remove duplicate values from the dataset.\n",
    "\n",
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Impute the missing values in the dataset.\n",
    "\n",
    "-   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Find how many duplicate rows exist in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicate rows in the dataframe is: 154\n"
     ]
    }
   ],
   "source": [
    "# Find how many duplicate rows exist in the dataframe\n",
    "duplicate_rows_count = df.duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The number of duplicate rows in the dataframe is: {duplicate_rows_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame before removing duplicates: (11552, 85)\n",
      "Shape of DataFrame after removing duplicates: (11398, 85)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from the dataframe\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Print information about the new DataFrame without duplicates\n",
    "print(\"Shape of DataFrame before removing duplicates:\", df.shape)\n",
    "print(\"Shape of DataFrame after removing duplicates:\", df_no_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates were successfully dropped.\n",
      "Shape of DataFrame without duplicates: (11398, 85)\n"
     ]
    }
   ],
   "source": [
    "# Verify if duplicates were actually dropped\n",
    "original_rows, original_columns = df.shape\n",
    "no_duplicates_rows, no_duplicates_columns = df_no_duplicates.shape\n",
    "\n",
    "if original_rows > no_duplicates_rows:\n",
    "    print(\"Duplicates were successfully dropped.\")\n",
    "else:\n",
    "    print(\"No duplicates found or duplicates were not dropped.\")\n",
    "\n",
    "# Display the shape of the new DataFrame without duplicates\n",
    "print(\"Shape of DataFrame without duplicates:\", df_no_duplicates.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for each column:\n",
      "Respondent        0\n",
      "MainBranch        0\n",
      "Hobbyist          0\n",
      "OpenSourcer       0\n",
      "OpenSource       81\n",
      "               ... \n",
      "Sexuality       547\n",
      "Ethnicity       683\n",
      "Dependents      144\n",
      "SurveyLength     19\n",
      "SurveyEase       14\n",
      "Length: 85, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find missing values for all columns\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display the missing values\n",
    "print(\"Missing values for each column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing rows in the 'WorkLoc' column is: 32\n"
     ]
    }
   ],
   "source": [
    "# Find out how many rows are missing in the 'WorkLoc' column\n",
    "missing_workloc_rows = df['WorkLoc'].isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The number of missing rows in the 'WorkLoc' column is: {missing_workloc_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the  value counts for the column WorkLoc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for the 'WorkLoc' column:\n",
      "Office                                            6905\n",
      "Home                                              3638\n",
      "Other place, such as a coworking space or cafe     977\n",
      "Name: WorkLoc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the value counts for the 'WorkLoc' column\n",
    "workloc_value_counts = df['WorkLoc'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(\"Value counts for the 'WorkLoc' column:\")\n",
    "print(workloc_value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent value in the 'WorkLoc' column is: Office\n"
     ]
    }
   ],
   "source": [
    "# Identify the most frequent value in the 'WorkLoc' column\n",
    "most_frequent_workloc = df['WorkLoc'].value_counts().idxmax()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The most frequent value in the 'WorkLoc' column is: {most_frequent_workloc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing rows in the 'WorkLoc' column after imputation is: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify the most frequent value in the 'WorkLoc' column\n",
    "most_frequent_workloc = df['WorkLoc'].value_counts().idxmax()\n",
    "\n",
    "# Impute (replace) empty rows in the 'WorkLoc' column with the most frequent value\n",
    "df['WorkLoc'] = df['WorkLoc'].fillna(most_frequent_workloc)\n",
    "\n",
    "# Verify the changes\n",
    "missing_workloc_after_imputation = df['WorkLoc'].isnull().sum()\n",
    "print(f\"The number of missing rows in the 'WorkLoc' column after imputation is: {missing_workloc_after_imputation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if imputing was successful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation was successful. There are no missing values in the 'WorkLoc' column.\n"
     ]
    }
   ],
   "source": [
    "# Verify if imputing was successful\n",
    "missing_workloc_after_imputation = df['WorkLoc'].isnull().sum()\n",
    "\n",
    "if missing_workloc_after_imputation == 0:\n",
    "    print(\"Imputation was successful. There are no missing values in the 'WorkLoc' column.\")\n",
    "else:\n",
    "    print(f\"Imputation was not successful. There are still {missing_workloc_after_imputation} missing values in the 'WorkLoc' column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in the 'CompFreq' column:\n",
      "['Yearly' 'Monthly' 'Weekly' nan]\n"
     ]
    }
   ],
   "source": [
    "# List out the various categories in the 'CompFreq' column\n",
    "compfreq_categories = df['CompFreq'].unique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Categories in the 'CompFreq' column:\")\n",
    "print(compfreq_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CompFreq  CompTotal  NormalizedAnnualCompensation\n",
      "0   Yearly    61000.0                       61000.0\n",
      "1   Yearly   138000.0                      138000.0\n",
      "2   Yearly    90000.0                       90000.0\n",
      "3  Monthly    29000.0                      348000.0\n",
      "4   Yearly    90000.0                       90000.0\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'NormalizedAnnualCompensation'\n",
    "df['NormalizedAnnualCompensation'] = df.apply(lambda row: row['CompTotal'] if row['CompFreq'] == 'Yearly'\n",
    "                                               else row['CompTotal'] * 12 if row['CompFreq'] == 'Monthly'\n",
    "                                               else row['CompTotal'] * 52 if row['CompFreq'] == 'Weekly'\n",
    "                                               else None, axis=1)\n",
    "\n",
    "# Display the updated DataFrame with the new column\n",
    "print(df[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
